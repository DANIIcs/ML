{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyRaofQFnaEb"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iziWh-8CnVJa"
      },
      "source": [
        "# An√°lisis de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J7Tyb5FnPSv"
      },
      "source": [
        "## Importaci√≥n del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MueQHl81m4DX",
        "outputId": "fff81f6b-e081-4717-c88d-b22f877d5c92"
      },
      "outputs": [],
      "source": [
        "# Nombre del archivo zip\n",
        "zip_path = \"archive.zip\"\n",
        "\n",
        "# Extraer todo el contenido\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"diabetes_dataset\")\n",
        "\n",
        "# Verificar archivos extra√≠dos\n",
        "print(\"Archivos extra√≠dos:\")\n",
        "print(os.listdir(\"diabetes_dataset\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_8dNdY1oWy2"
      },
      "source": [
        "Existen 3 datasets:\n",
        "\n",
        "\n",
        "* df_original: Muestra m√°s representativa de la realidad por la distribuci√≥n desbalanceada de clases. La variable objetivo Diabetes_012 tiene 3 clases: 0 indica sin diabetes o diabetes solo durante el embarazo, 1 indica prediabetes y 2 indica diabetes.\n",
        "\n",
        "* df_balanceado: Muestra balanceada artificialmente al 50% para cada clase. La variable objetivo Diabetes_binary tiene 2 clases: 0 es sin diabetes y 1 es prediabetes o diabetes.\n",
        "\n",
        "* df_binario:  Muestra no balanceada de encuestas. La variable objetivo Diabetes_binary tiene 2 clases: 0 es sin diabetes y 1 es prediabetes o diabetes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "K5I8J7Lonl8o",
        "outputId": "b938390f-1ffe-4685-d997-bb94e80d3229"
      },
      "outputs": [],
      "source": [
        "# Cargar\n",
        "df_original = pd.read_csv(r\"D:\\Principal\\ML\\diabetes_dataset\\diabetes_012_health_indicators_BRFSS2015.csv\")\n",
        "\n",
        "# Vista previa del dataset\n",
        "df_original.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "1knBTpabqJHn",
        "outputId": "d29987d1-a920-4df2-b558-063fb07f0166"
      },
      "outputs": [],
      "source": [
        "# Cargar\n",
        "df_balanceado = pd.read_csv(r\"D:\\Principal\\ML\\diabetes_dataset\\diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
        "\n",
        "# Vista previa del dataset\n",
        "df_balanceado.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "ZRemIoQSqJlh",
        "outputId": "7462c518-86e7-4469-8b53-8f355c57363c"
      },
      "outputs": [],
      "source": [
        "# Cargar\n",
        "df_binario = pd.read_csv(r\"D:\\Principal\\ML\\diabetes_dataset\\diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
        "\n",
        "# Vista previa del dataset\n",
        "df_binario.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igXAw7a8q4Ps"
      },
      "source": [
        "## An√°lisis de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHlucGDlrzQP"
      },
      "source": [
        "### Caracteristicas principales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "tyalP1PAsbh8",
        "outputId": "776cdf74-0c08-4e09-8c0f-deda50958d1c"
      },
      "outputs": [],
      "source": [
        "# Obtener distribuci√≥n en porcentaje por dataset\n",
        "dist_original = df_original['Diabetes_012'].value_counts(normalize=True).sort_index() * 100\n",
        "dist_balanceado = df_balanceado['Diabetes_binary'].value_counts(normalize=True).sort_index() * 100\n",
        "dist_binario = df_binario['Diabetes_binary'].value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "# Construcci√≥n de la tabla\n",
        "tabla = pd.DataFrame({\n",
        "    'df_original (0=sin, 1=prediab, 2=diab)': [\n",
        "        df_original.shape[0],\n",
        "        df_original.isnull().sum().sum(),\n",
        "        dist_original.get(0, 0),\n",
        "        dist_original.get(1, 0),\n",
        "        dist_original.get(2, 0)\n",
        "    ],\n",
        "    'df_balanceado (0=sin, 1=prediab+diab)': [\n",
        "        df_balanceado.shape[0],\n",
        "        df_balanceado.isnull().sum().sum(),\n",
        "        dist_balanceado.get(0, 0),\n",
        "        dist_balanceado.get(1, 0),\n",
        "        0  # Clase 2 no aplica\n",
        "    ],\n",
        "    'df_binario (0=sin, 1=prediab+diab)': [\n",
        "        df_binario.shape[0],\n",
        "        df_binario.isnull().sum().sum(),\n",
        "        dist_binario.get(0, 0),\n",
        "        dist_binario.get(1, 0),\n",
        "        0  # Clase 2 no aplica\n",
        "    ]\n",
        "}, index=[\n",
        "    \"Tama√±o del dataset\",\n",
        "    \"Total de valores nulos\",\n",
        "    \"Clase 0 (%)\",\n",
        "    \"Clase 1 (%)\",\n",
        "    \"Clase 2 (%)\"\n",
        "])\n",
        "\n",
        "# Mostrar la tabla redondeada\n",
        "tabla = tabla.round(2)\n",
        "from IPython.display import display\n",
        "display(tabla)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "5QmWzADhtr9i",
        "outputId": "01293a64-56a4-4f13-ca35-6c99fb40eb96"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
        "\n",
        "df_original['Diabetes_012'].value_counts().sort_index().plot(kind='bar', ax=axes[0], title='df_original')\n",
        "axes[0].set_xlabel(\"Clase\"); axes[0].set_ylabel(\"Frecuencia\"); axes[0].set_ylim(0, 230000)\n",
        "\n",
        "df_balanceado['Diabetes_binary'].value_counts().sort_index().plot(kind='bar', ax=axes[1], title='df_balanceado')\n",
        "axes[1].set_xlabel(\"Clase\"); axes[1].set_ylim(0, 230000)\n",
        "\n",
        "df_binario['Diabetes_binary'].value_counts().sort_index().plot(kind='bar', ax=axes[2], title='df_binario')\n",
        "axes[2].set_xlabel(\"Clase\"); axes[2].set_ylim(0, 230000)\n",
        "\n",
        "plt.suptitle(\"Distribuci√≥n de la variable objetivo\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHpzI33hvHt_"
      },
      "source": [
        "Distribuci√≥n de variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "h_DGROYgt32B",
        "outputId": "330bfc00-bed8-4bdd-c5ca-4a2c56f3c3ea"
      },
      "outputs": [],
      "source": [
        "# Detectar variables binarias (con solo 2 valores √∫nicos)\n",
        "def get_binarias(df):\n",
        "    return [col for col in df.columns if df[col].nunique() == 2 and col not in ['Diabetes_012', 'Diabetes_binary']]\n",
        "\n",
        "# Detectar variables continuas (m√°s de 2 valores √∫nicos)\n",
        "def get_continuas(df):\n",
        "    return [col for col in df.columns if df[col].nunique() > 2 and col not in ['Diabetes_012', 'Diabetes_binary']]\n",
        "\n",
        "# Funci√≥n para graficar variables binarias en barras apiladas\n",
        "def plot_barras_binarias(df, nombre):\n",
        "    vars_binarias = get_binarias(df)\n",
        "    counts = df[vars_binarias].apply(pd.Series.value_counts).T.fillna(0)\n",
        "    counts[[0, 1]].plot(kind='bar', stacked=True, figsize=(10, 5), color=['lightgray', 'steelblue'])\n",
        "    plt.title(f\"Distribuci√≥n de variables binarias - {nombre}\")\n",
        "    plt.xlabel(\"Variable\")\n",
        "    plt.ylabel(\"Frecuencia\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title=\"Valor\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_barras_binarias(df_original, \"df_original\")\n",
        "plot_barras_binarias(df_balanceado, \"df_balanceado\")\n",
        "#plot_barras_binarias(df_binario, \"df_binario\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "h-Fd_c2DxLhZ",
        "outputId": "bf547d0c-478f-4155-e65a-2532ecfd4927"
      },
      "outputs": [],
      "source": [
        "def resumen_continuas(df, nombre):\n",
        "    vars_continuas = get_continuas(df)\n",
        "    resumen = pd.DataFrame({\n",
        "        'Variable': vars_continuas,\n",
        "        'Media': [df[col].mean() for col in vars_continuas],\n",
        "        'Desviaci√≥n est√°ndar': [df[col].std() for col in vars_continuas],\n",
        "        'M√≠nimo': [df[col].min() for col in vars_continuas],\n",
        "        'M√°ximo': [df[col].max() for col in vars_continuas],\n",
        "    })\n",
        "    resumen = resumen.round(2)\n",
        "    print(f\"Estad√≠sticas de variables continuas - {nombre}\")\n",
        "    display(resumen)\n",
        "\n",
        "# Mostrar tabla para cada dataset\n",
        "resumen_continuas(df_original, \"df_original\")\n",
        "resumen_continuas(df_balanceado, \"df_balanceado\")\n",
        "#resumen_continuas(df_binario, \"df_binario\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24N8_vyuuGte",
        "outputId": "2f067102-b882-42d8-c3f0-42d6f16d3a6a"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n para listar variables no num√©ricas\n",
        "def get_categoricas(df, nombre):\n",
        "    no_numericas = df.select_dtypes(exclude=['number']).columns.tolist()\n",
        "    print(f\"\\nVariables no num√©ricas en {nombre}:\")\n",
        "    if no_numericas:\n",
        "        for col in no_numericas:\n",
        "            print(f\" - {col}\")\n",
        "    else:\n",
        "        print(\" (No se encontraron variables no num√©ricas)\")\n",
        "\n",
        "get_categoricas(df_original, \"df_original\")\n",
        "get_categoricas(df_balanceado, \"df_balanceado\")\n",
        "#get_categoricas(df_binario, \"df_binario\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz6AkmXIuFE9"
      },
      "source": [
        "### Correlaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "EYJOJpSUrA9m",
        "outputId": "ac83c59b-c3a9-4f97-ec3c-76630ce7b67b"
      },
      "outputs": [],
      "source": [
        "# Obtener variables num√©ricas comunes (excluyendo variable objetivo)\n",
        "vars_comunes = [col for col in df_original.columns if col in df_balanceado.columns and col in df_binario.columns]\n",
        "vars_comunes = [col for col in vars_comunes if col not in ['Diabetes_012', 'Diabetes_binary']]\n",
        "\n",
        "# Calcular correlaciones individuales\n",
        "corr_o = df_original[vars_comunes + ['Diabetes_012']].corr()['Diabetes_012'].drop('Diabetes_012')\n",
        "corr_ba = df_balanceado[vars_comunes + ['Diabetes_binary']].corr()['Diabetes_binary'].drop('Diabetes_binary')\n",
        "corr_bi = df_binario[vars_comunes + ['Diabetes_binary']].corr()['Diabetes_binary'].drop('Diabetes_binary')\n",
        "\n",
        "# Unificar el orden por correlaci√≥n en df_original\n",
        "corr_o = corr_o.sort_values(ascending=False)\n",
        "order = corr_o.index.tolist()\n",
        "corr_ba = corr_ba.loc[order]\n",
        "corr_bi = corr_bi.loc[order]\n",
        "\n",
        "# Crear figura con 3 subplots en una fila\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, len(order)*0.4), sharey=True)\n",
        "\n",
        "# Plot para df_original\n",
        "sns.heatmap(corr_o.to_frame(), annot=True, cmap='coolwarm', center=0, ax=axes[0], cbar=False)\n",
        "axes[0].set_title(\"df_original\")\n",
        "axes[0].set_xlabel(\"Correlaci√≥n\")\n",
        "axes[0].set_ylabel(\"Variable\")\n",
        "\n",
        "# Plot para df_balanceado\n",
        "sns.heatmap(corr_ba.to_frame(), annot=True, cmap='coolwarm', center=0, ax=axes[1], cbar=False)\n",
        "axes[1].set_title(\"df_balanceado\")\n",
        "axes[1].set_xlabel(\"Correlaci√≥n\")\n",
        "axes[1].set_ylabel(\"\")\n",
        "\n",
        "# Plot para df_binario\n",
        "sns.heatmap(corr_bi.to_frame(), annot=True, cmap='coolwarm', center=0, ax=axes[2], cbar_kws={'label': 'Coef. de correlaci√≥n'})\n",
        "axes[2].set_title(\"df_binario\")\n",
        "axes[2].set_xlabel(\"Correlaci√≥n\")\n",
        "axes[2].set_ylabel(\"\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiwLI8VjznF9"
      },
      "source": [
        "## Preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suc-SEVgzpAz"
      },
      "source": [
        "Se excluiran de los datasets todas las variables con una correlacion absoluta menor o igual a 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrfh6iQUzom0",
        "outputId": "08849766-f02b-4327-bd86-0594b2ad8ba3"
      },
      "outputs": [],
      "source": [
        "# Para df_original\n",
        "corr_o = df_original.corr()['Diabetes_012'].drop('Diabetes_012')\n",
        "vars_o = corr_o[abs(corr_o) > 0.1].index.tolist()\n",
        "df_original_filtrado = df_original[vars_o + ['Diabetes_012']]\n",
        "print(f\"df_original: {len(vars_o)} variables seleccionadas\")\n",
        "print(\"Variables conservadas:\", vars_o)\n",
        "\n",
        "# Para df_balanceado\n",
        "corr_ba = df_balanceado.corr()['Diabetes_binary'].drop('Diabetes_binary')\n",
        "vars_ba = corr_ba[abs(corr_ba) > 0.1].index.tolist()\n",
        "df_balanceado_filtrado = df_balanceado[vars_ba + ['Diabetes_binary']]\n",
        "print(f\"df_balanceado: {len(vars_ba)} variables seleccionadas\")\n",
        "print(\"Variables conservadas:\", vars_ba)\n",
        "\n",
        "# Para df_binario\n",
        "corr_bi = df_binario.corr()['Diabetes_binary'].drop('Diabetes_binary')\n",
        "vars_bi = corr_bi[abs(corr_bi) > 0.1].index.tolist()\n",
        "df_binario_filtrado = df_binario[vars_bi + ['Diabetes_binary']]\n",
        "print(f\"df_binario: {len(vars_bi)} variables seleccionadas\")\n",
        "print(\"Variables conservadas:\", vars_bi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Amrm71_IrC8s"
      },
      "outputs": [],
      "source": [
        "def preprocesar(df, target_col, usar_estratificacion=True):\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    if usar_estratificacion:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "    # Escalado est√°ndar a las variables num√©ricas\n",
        "    vars_continuas = get_continuas(df)\n",
        "    scaler = StandardScaler()\n",
        "    X_train[vars_continuas] = scaler.fit_transform(X_train[vars_continuas])\n",
        "    X_test[vars_continuas] = scaler.fit_transform(X_test[vars_continuas])\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, scaler\n",
        "\n",
        "\n",
        "# Dataset original (multiclase desbalanceado): S√ç estratificar\n",
        "Xo_train, Xo_test, yo_train, yo_test, scaler_o = preprocesar(df_original_filtrado, 'Diabetes_012', usar_estratificacion=True)\n",
        "\n",
        "# Dataset balanceado: NO estratificar\n",
        "Xb_train, Xb_test, yb_train, yb_test, scaler_b = preprocesar(df_balanceado_filtrado, 'Diabetes_binary', usar_estratificacion=False)\n",
        "\n",
        "# Dataset binario desbalanceado: S√ç estratificar\n",
        "Xbi_train, Xbi_test, ybi_train, ybi_test, scaler_bi = preprocesar(df_binario_filtrado, 'Diabetes_binary', usar_estratificacion=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj5M5ZiK1p-k"
      },
      "source": [
        "# Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNIaQ5Km16-m"
      },
      "outputs": [],
      "source": [
        "def evaluar_modelos_con_matriz(X_train, X_test, y_train, y_test, nombre_dataset,\n",
        "                               k, c, kern, depth, crit, min_ss):\n",
        "    print(f\"Evaluaci√≥n de modelos - {nombre_dataset}\")\n",
        "\n",
        "    modelos = {\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=k),\n",
        "        \"Regresi√≥n Log√≠stica\": LogisticRegression(C=c, max_iter=100),\n",
        "        #\"SVM\": SVC(kernel=kern),\n",
        "        \"√Årbol de Decisi√≥n\": DecisionTreeClassifier(max_depth=depth, criterion=crit, min_samples_split=min_ss)\n",
        "    }\n",
        "\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
        "\n",
        "    for idx, (nombre, modelo) in enumerate(modelos.items()):\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_test)\n",
        "\n",
        "        #acc = accuracy_score(y_test, y_pred)\n",
        "        if len(y_test.unique()) == 2:\n",
        "            f1 = f1_score(y_test, y_pred, average='binary')\n",
        "        else:\n",
        "          f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "        print(f\"\\nüîπ Modelo: {nombre}\")\n",
        "        #print(f\"Accuracy: {acc:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "        # Matriz de confusi√≥n\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
        "        axes[idx].set_title(nombre)\n",
        "        axes[idx].set_xlabel('Predicho')\n",
        "        axes[idx].set_ylabel('Real')\n",
        "\n",
        "    plt.suptitle(f\"Matrices de confusi√≥n - {nombre_dataset}\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVKpRcS-1vfA"
      },
      "source": [
        "## DF Original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "UoAYAaBrwogD",
        "outputId": "dab8649f-79d5-4980-90df-462aabc4d45f"
      },
      "outputs": [],
      "source": [
        "# Grid search para encontrar los mejores parametros del KNN\n",
        "params_knn = {'n_neighbors': [2, 3, 5]}\n",
        "scorer = make_scorer(f1_score, average='macro') # Usar F1 como m√©trica a optimizar\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid=params_knn, scoring=scorer, cv=10)\n",
        "grid.fit(Xo_train, yo_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "SRVbq6atxOSC",
        "outputId": "fdb274fe-04f1-41ca-8b8c-7e95492b8dcb"
      },
      "outputs": [],
      "source": [
        "# Grid search para encontrar los mejores par√°metros de regresi√≥n log√≠stica\n",
        "params_regresion = {'C': [0.01, 0.1, 1]}\n",
        "# C : default=1.0\n",
        "# Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid=params_regresion, scoring=scorer, cv=10)\n",
        "grid.fit(Xo_train, yo_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "8U3bXezoxhXd",
        "outputId": "dcafe563-8699-49e0-f9f9-18325fcf0734"
      },
      "outputs": [],
      "source": [
        "# Grid search para encontrar los mejores parametros del arbol de decision\n",
        "params_arbol = {\n",
        "    'max_depth': [7, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'criterion': ['gini', 'entropy', 'log_loss']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=params_arbol, scoring=scorer, cv=10)\n",
        "grid.fit(Xo_train, yo_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "3VQBp6Fk239V",
        "outputId": "f4b3d49b-3feb-4447-e377-de3e8049fa8d"
      },
      "outputs": [],
      "source": [
        "neighbors = 3\n",
        "c = 1\n",
        "kern = 'rbf'\n",
        "depth = None\n",
        "crit = 'log_loss'\n",
        "min_ss = 2\n",
        "\n",
        "evaluar_modelos_con_matriz(Xo_train, Xo_test, yo_train, yo_test, \"df_original\",\n",
        "                                      neighbors, c, kern, depth, crit, min_ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLQ4mTRx1z2q"
      },
      "source": [
        "## DF Balanceado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "-snrbxMyy47r",
        "outputId": "4022b98b-8e82-43d5-d078-6246f87c4aae"
      },
      "outputs": [],
      "source": [
        "# Mejores par√°metros para el dataset balanceado\n",
        "neighbors = 9\n",
        "c = 10\n",
        "kern = 'rbf'\n",
        "depth = 7\n",
        "crit = 'entropy'\n",
        "min_ss = 5\n",
        "\n",
        "evaluar_modelos_con_matriz(Xb_train, Xb_test, yb_train, yb_test, \"df_balanceado\",\n",
        "                                      neighbors, c, kern, depth, crit, min_ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjYJzy1212SY"
      },
      "source": [
        "## DF binario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "49dQq3cQ3fR4",
        "outputId": "822155c1-4c14-44b0-ffd8-eff30e37e204"
      },
      "outputs": [],
      "source": [
        "# Mejores par√°metros para el dataset binario\n",
        "neighbors = 3\n",
        "c = 10\n",
        "kern = 'rbf'\n",
        "depth = None\n",
        "crit = 'entropy'\n",
        "min_ss = 2\n",
        "\n",
        "evaluar_modelos_con_matriz(Xbi_train, Xbi_test, ybi_train, ybi_test, \"df_binario\",\n",
        "                                      neighbors, c, kern, depth, crit, min_ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8hi6tLhPyy3"
      },
      "source": [
        "SVM - Dataset Original (df_original, multiclase desbalanceado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Importar librer√≠as necesarias\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‚ö†Ô∏è Aseg√∫rate de tener ejecutado esto antes:\n",
        "# Xo_train, Xo_test, yo_train, yo_test, scaler_o = preprocesar(...)\n",
        "\n",
        "# üîª Reducir tama√±o del dataset para entrenamiento final (30,000 muestras)\n",
        "Xo_train_reduced, yo_train_reduced = resample(\n",
        "    Xo_train, yo_train, n_samples=30000, stratify=yo_train, random_state=42\n",
        ")\n",
        "\n",
        "# ‚úÖ Entrenar SVM con los mejores par√°metros encontrados\n",
        "modelo_svm_o = SVC(C=10, kernel='rbf', gamma='auto')\n",
        "modelo_svm_o.fit(Xo_train_reduced, yo_train_reduced)\n",
        "\n",
        "# üß† Predecir con el conjunto de prueba completo\n",
        "y_pred_o = modelo_svm_o.predict(Xo_test)\n",
        "\n",
        "# üìä Mostrar el reporte de m√©tricas\n",
        "print(\"\\nüìä Reporte SVM - df_original (entrenado con muestra):\")\n",
        "print(classification_report(yo_test, y_pred_o))\n",
        "\n",
        "# üî∑ Matriz de confusi√≥n\n",
        "sns.heatmap(confusion_matrix(yo_test, y_pred_o), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"SVM - df_original (entrenado con muestra de 30k)\")\n",
        "plt.xlabel(\"Predicci√≥n\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh5lLfBGbpgT"
      },
      "source": [
        "SVM - Dataset Balanceado (df_balanceado, binario balanceado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pagf4zFobqPk"
      },
      "outputs": [],
      "source": [
        "# Grid Search para encontrar los mejores par√°metros\n",
        "param_grid_svm_b = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_svm_b = GridSearchCV(SVC(), param_grid=param_grid_svm_b, cv=5)\n",
        "grid_svm_b.fit(Xb_train, yb_train)\n",
        "print(\"üîç Mejores par√°metros SVM - df_balanceado:\", grid_svm_b.best_params_)\n",
        "\n",
        "# Entrenamiento y evaluaci√≥n final\n",
        "modelo_svm_b = SVC(**grid_svm_b.best_params_)\n",
        "modelo_svm_b.fit(Xb_train, yb_train)\n",
        "y_pred_b = modelo_svm_b.predict(Xb_test)\n",
        "\n",
        "print(\"\\nüìä Reporte SVM - df_balanceado:\")\n",
        "print(classification_report(yb_test, y_pred_b))\n",
        "\n",
        "sns.heatmap(confusion_matrix(yb_test, y_pred_b), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"SVM - df_balanceado\")\n",
        "plt.xlabel(\"Predicci√≥n\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNQZu3dmbusT"
      },
      "source": [
        "SVM - Dataset Binario Real (df_binario, binario desbalanceado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-fx7_Ppbyla"
      },
      "outputs": [],
      "source": [
        "# Grid Search para encontrar los mejores par√°metros\n",
        "param_grid_svm_bi = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_svm_bi = GridSearchCV(SVC(), param_grid=param_grid_svm_bi, cv=5)\n",
        "grid_svm_bi.fit(Xbi_train, ybi_train)\n",
        "print(\"üîç Mejores par√°metros SVM - df_binario:\", grid_svm_bi.best_params_)\n",
        "\n",
        "# Entrenamiento y evaluaci√≥n final\n",
        "modelo_svm_bi = SVC(**grid_svm_bi.best_params_)\n",
        "modelo_svm_bi.fit(Xbi_train, ybi_train)\n",
        "y_pred_bi = modelo_svm_bi.predict(Xbi_test)\n",
        "\n",
        "print(\"\\nüìä Reporte SVM - df_binario:\")\n",
        "print(classification_report(ybi_test, y_pred_bi))\n",
        "\n",
        "sns.heatmap(confusion_matrix(ybi_test, y_pred_bi), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"SVM - df_binario\")\n",
        "plt.xlabel(\"Predicci√≥n\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
