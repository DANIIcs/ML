{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "58e65a9f",
      "metadata": {
        "id": "58e65a9f"
      },
      "source": [
        " # Hackaton Clasification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4FEfWmwDDPju",
      "metadata": {
        "id": "4FEfWmwDDPju"
      },
      "source": [
        "Resuelva este laboratorio y rellene la [ficha](https://docs.google.com/spreadsheets/d/1JopiqKvH4S3HX6FRvpLRI4LHxmXvRTYYCxmRwgOl95Y/edit?usp=sharing) reportando sus hallazgos.\n",
        "\n",
        "La data la pueden encontrar en este [drive](https://drive.google.com/drive/folders/1I0IDa5PuG9HkgbROP6gU-H0uIB6kiLvO?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d470512",
      "metadata": {
        "id": "8d470512"
      },
      "source": [
        "1.  Decídase por un modelo, el que mejor le funcione. Si usa los 3 (SVM, RL o DT), indíquelo en su  ficha de google drive.\n",
        "2.  Coloque el máximo accuracy alcanzado por su modelo o por sus modelos.\n",
        "3.  Importante: Use una semilla para replicar su código.\n",
        "4.  Sólo aquellos códigos en colab que generen exactamente el mismo resultado que los reportados en esta ficha serán tomados en cuenta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8766f39",
      "metadata": {
        "id": "f8766f39"
      },
      "source": [
        "## DATA: Hojas de saludables y no saludables de plantas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-WB7B9Xa4drM",
      "metadata": {
        "id": "-WB7B9Xa4drM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8c85b99d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-02T07:05:12.038089Z",
          "start_time": "2025-05-02T07:04:55.807109Z"
        },
        "id": "8c85b99d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Reproducibilidad\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e876e15b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Archivos descomprimidos correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Rutas de los archivos ZIP\n",
        "zip_train = \"train-20250505T191631Z-001.zip\"\n",
        "zip_test = \"test-20250505T191630Z-001.zip\"\n",
        "extract_path = \"Data_plantas\"\n",
        "\n",
        "# Descomprimir train\n",
        "with zipfile.ZipFile(zip_train, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(extract_path, 'train'))\n",
        "\n",
        "# Descomprimir test\n",
        "with zipfile.ZipFile(zip_test, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(extract_path, 'test'))\n",
        "\n",
        "print(\"✅ Archivos descomprimidos correctamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b73ba8d95f6f7ac",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-02T07:15:10.050059Z",
          "start_time": "2025-05-02T07:15:10.043640Z"
        },
        "id": "2b73ba8d95f6f7ac"
      },
      "outputs": [],
      "source": [
        "def encode(path, data_type='train', img_size=(64, 64)):\n",
        "    data = []\n",
        "\n",
        "    label_map = {\n",
        "        \"Healthy\": -1,\n",
        "        \"Unhealthy\": 1\n",
        "    }\n",
        "\n",
        "    base_path = os.path.join(path, data_type)\n",
        "\n",
        "    for label_name, label_value in label_map.items():\n",
        "        folder_path = os.path.join(base_path, label_name)\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"Advertencia: carpeta no encontrada {folder_path}\")\n",
        "            continue\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img_path = os.path.join(folder_path, file)\n",
        "                try:\n",
        "                    img = Image.open(img_path).resize(img_size).convert('RGB')\n",
        "                    img_array = np.array(img).flatten()\n",
        "                    data.append([label_value, *img_array])\n",
        "                except Exception as e:\n",
        "                    print(f\"Error cargando {file}: {e}\")\n",
        "\n",
        "    data = np.array(data)\n",
        "    np.random.shuffle(data)\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "hVAIgZ7FB1CH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "hVAIgZ7FB1CH",
        "outputId": "bd01c79c-5057-4a55-ab75-57789d00f19c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (5703, 12288) (5703,)\n",
            "Test: (1105, 12288) (1105,)\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"Data_plantas\"\n",
        "\n",
        "x_train, y_train = encode(dataset_path, data_type='train')\n",
        "x_test, y_test = encode(dataset_path, data_type='test')\n",
        "\n",
        "print(\"Train:\", x_train.shape, y_train.shape)\n",
        "print(\"Test:\", x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b302ffc1d3f9184d",
      "metadata": {
        "id": "b302ffc1d3f9184d"
      },
      "source": [
        "# Model\n",
        "\n",
        "Apply the following classification models: SVM, Decision Trees, and Logistic Regression. Evaluate their performance using the metrics Accuracy, Precision, Recall, and F1 Score. Compare the results and present the model with the best performance.\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "### Módelos de clasificación\n",
        "\n",
        "\n",
        "| **Modelo**                  | **Descripción**                                                 | **Enlace a la documentación y ejemplos**                       |\n",
        "|-----------------------------|-----------------------------------------------------------------|---------------------------------------------------------------|\n",
        "| **Support Vector Machine (SVM)** | Encuentra el hiperplano óptimo para separar clases.           | [SVM - scikit-learn](https://scikit-learn.org/stable/modules/svm.html) |\n",
        "| **Árbol de Decisión**       | Clasificador que utiliza un árbol jerárquico basado en reglas.   | [Decision Tree - scikit-learn](https://scikit-learn.org/stable/modules/tree.html#classification) |\n",
        "| **Regresión Logística**     | Clasificador lineal basado en probabilidades.                   | [Logistic Regression - scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) |\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bbb667183f9b128",
      "metadata": {
        "id": "5bbb667183f9b128"
      },
      "source": [
        "### LOGISTIC REGRESSION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eNm4C1vt-KN7",
      "metadata": {
        "id": "eNm4C1vt-KN7"
      },
      "source": [
        "**0. Inicialización de parámetros**\n",
        "\n",
        "Se inicializan los pesos `w` y el bias `b` en cero.\n",
        "\n",
        "La predicción se define como:\n",
        "\n",
        "$$\n",
        "\\hat{y}^{(i)} = \\sigma(\\mathbf{w}^T \\mathbf{x}^{(i)} + b)\n",
        "$$\n",
        "\n",
        "donde $\\sigma(z)$ es la función sigmoide:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6g6ZlA4-SrS",
      "metadata": {
        "id": "d6g6ZlA4-SrS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def inicializar_parametros(n_features):\n",
        "    w = np.zeros((n_features, 1))\n",
        "    b = 0.0\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xSAbkdaxsIui",
      "metadata": {
        "id": "xSAbkdaxsIui"
      },
      "source": [
        "**1. Predicción de la probabilidad**\n",
        "\n",
        "Modelamos la probabilidad de que la clase sea 1 con una función sigmoide:\n",
        "\n",
        "$$\n",
        "P(y=1 \\mid \\mathbf{x}) = \\sigma(z), \\quad \\text{donde} \\quad z = \\mathbf{w}^T \\mathbf{x} + b\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J3efDbm_sH29",
      "metadata": {
        "id": "J3efDbm_sH29"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HDVqm9F1tCHx",
      "metadata": {
        "id": "HDVqm9F1tCHx"
      },
      "source": [
        "**2. Función de pérdida (Log-loss)**\n",
        "\n",
        "Se utiliza la pérdida logarítmica como función de costo:\n",
        "\n",
        "$$\n",
        "J(\\mathbf{w}, b) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1TvsqDVNtJ7m",
      "metadata": {
        "id": "1TvsqDVNtJ7m"
      },
      "outputs": [],
      "source": [
        "def compute_loss(y, y_hat):\n",
        "  #TO DO\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0JZcsSCJt_OJ",
      "metadata": {
        "id": "0JZcsSCJt_OJ"
      },
      "source": [
        "**3. Gradientes**\n",
        "\n",
        "Los gradientes respecto a los parámetros son:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)}) x_j^{(i)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7m1YqopgvW2K",
      "metadata": {
        "id": "7m1YqopgvW2K"
      },
      "outputs": [],
      "source": [
        "def compute_gradients(X, y, y_hat):\n",
        "    dw = 0 #TO DO\n",
        "    db = 0 # TO DO\n",
        "    #TO DO\n",
        "    return dw, db"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e-jUKM1vyPF",
      "metadata": {
        "id": "6e-jUKM1vyPF"
      },
      "source": [
        "**4. Entrenamiento del modelo**\n",
        "\n",
        "Se entrena usando descenso de gradiente durante varias iteraciones:\n",
        "\n",
        "$$\n",
        "w := w - \\alpha \\cdot \\frac{\\partial J}{\\partial w}, \\quad b := b - \\alpha \\cdot \\frac{\\partial J}{\\partial b}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JGEp5vccvz_G",
      "metadata": {
        "id": "JGEp5vccvz_G"
      },
      "outputs": [],
      "source": [
        "def train_logistic_regression(X, y, epochs=1000, lr=0.1):\n",
        "    n_features = X.shape[1]\n",
        "    w, b = inicializar_parametros(n_features)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        dw, db = calcular_gradientes(w, b, X, y)\n",
        "        w -= lr * dw\n",
        "        b -= lr * db\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            costo = compute_loss(w, b, X, y)\n",
        "            print(f\"Iteración {i} - Costo: {costo:.4f}\")\n",
        "\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rVA3I_FzkafE",
      "metadata": {
        "id": "rVA3I_FzkafE"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O9Nh3OGWxa1O",
      "metadata": {
        "id": "O9Nh3OGWxa1O"
      },
      "source": [
        "**1. Hiperplano de decisión**\n",
        "\n",
        "La frontera de decisión de una SVM es una función lineal:\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} + b\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "miG2tvlCxai0",
      "metadata": {
        "id": "miG2tvlCxai0"
      },
      "outputs": [],
      "source": [
        "def decision_function(X, w, b):\n",
        "    return #TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eqHNY6731tN6",
      "metadata": {
        "id": "eqHNY6731tN6"
      },
      "source": [
        "**2. Función de pérdida hinge con regularización**\n",
        "\n",
        "La función objetivo para SVM (soft margin) es:\n",
        "\n",
        "$$\n",
        "J(\\mathbf{w}, b) = \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^m \\max(0, 1 - y_i f(\\mathbf{x}_i))\n",
        "$$\n",
        "\n",
        "Donde $C$ es un hiperparámetro que controla el trade-off entre el margen y los errores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bwMcX0gv1swe",
      "metadata": {
        "id": "bwMcX0gv1swe"
      },
      "outputs": [],
      "source": [
        "def loss_hinge(X, y, w, b, C):\n",
        "    \"\"\"\n",
        "    Calcula la función de pérdida hinge con regularización.\n",
        "\n",
        "    Parámetros:\n",
        "        X: datos de entrada (m x n)\n",
        "        y: etiquetas en {-1, 1}\n",
        "        w: vector de pesos\n",
        "        b: sesgo\n",
        "        C: parámetro de regularización\n",
        "\n",
        "    Retorna:\n",
        "        pérdida total\n",
        "    \"\"\"\n",
        "    m = X.shape[0]\n",
        "    distances = 0 #TO DO\n",
        "    losses = 0 # TO DO\n",
        "    return # TO DO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vb4YVzw52MaJ",
      "metadata": {
        "id": "Vb4YVzw52MaJ"
      },
      "source": [
        "**3. Gradiente subgradiente de la función hinge**\n",
        "\n",
        "Para optimizar por descenso de gradiente, usamos el subgradiente:\n",
        "\n",
        "- Si $1 - y_i f(\\mathbf{x}_i) > 0$, entonces:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial J}{\\partial \\mathbf{w}} = \\mathbf{w} - C y_i \\mathbf{x}_i\n",
        "$$\n",
        "\n",
        "- Si $1 - y_i f(\\mathbf{x}_i) \\leq 0$, entonces:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial J}{\\partial \\mathbf{w}} = \\mathbf{w}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A-PqrL2izXIW",
      "metadata": {
        "id": "A-PqrL2izXIW"
      },
      "outputs": [],
      "source": [
        "def calcular_gradientes(X, y, w, b, C):\n",
        "    \"\"\"\n",
        "    Calcula los gradientes de la función de pérdida hinge.\n",
        "\n",
        "    Parámetros:\n",
        "        X: datos de entrada (muestras x características)\n",
        "        y: etiquetas (-1 o 1)\n",
        "        w: vector de pesos\n",
        "        b: sesgo\n",
        "        C: parámetro de regularización\n",
        "\n",
        "    Retorna:\n",
        "        grad_w: gradiente respecto a w\n",
        "        grad_b: gradiente respecto a b\n",
        "    \"\"\"\n",
        "    m, n = X.shape\n",
        "    grad_w = np.zeros_like(w)\n",
        "    grad_b = 0\n",
        "    # TO DO\n",
        "    return grad_w, grad_b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3lmjA6Fz2d2L",
      "metadata": {
        "id": "3lmjA6Fz2d2L"
      },
      "source": [
        "**4. Entrenamiento del modelo (descenso de gradiente)**\n",
        "\n",
        "Entrenamos el modelo actualizando los parámetros:\n",
        "\n",
        "$$\n",
        "\\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{w}}, \\quad\n",
        "b \\leftarrow b - \\alpha \\frac{\\partial J}{\\partial b}\n",
        "$$\n",
        "\n",
        "donde $\\alpha$ es la tasa de aprendizaje.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cx_6oOq52ilr",
      "metadata": {
        "id": "cx_6oOq52ilr"
      },
      "outputs": [],
      "source": [
        "def entrenar_svm(X, y, C=1.0, lr=0.01, epochs=1000):\n",
        "    \"\"\"\n",
        "    Entrena un clasificador SVM desde cero.\n",
        "\n",
        "    Parámetros:\n",
        "        X: datos de entrada (m x n)\n",
        "        y: etiquetas (0 o 1) → serán transformadas a (-1, 1)\n",
        "        C: parámetro de regularización\n",
        "        lr: tasa de aprendizaje\n",
        "        epochs: número de iteraciones\n",
        "\n",
        "    Retorna:\n",
        "        w: pesos entrenados\n",
        "        b: sesgo entrenado\n",
        "    \"\"\"\n",
        "    m, n = X.shape\n",
        "    y_transf = np.where(y == 0, -1, 1)\n",
        "    w = np.zeros(n)\n",
        "    b = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        grad_w, grad_b = calcular_gradientes(X, y_transf, w, b, C)\n",
        "        w -= lr * grad_w\n",
        "        b -= lr * grad_b\n",
        "\n",
        "    return w, b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Eqzrwi_4pPud",
      "metadata": {
        "id": "Eqzrwi_4pPud"
      },
      "source": [
        "## DECISION TREE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KVgLOzDd33_v",
      "metadata": {
        "id": "KVgLOzDd33_v"
      },
      "source": [
        "**1. Impureza del nodo**\n",
        "\n",
        "Para evaluar qué tan mezclado está un nodo, usamos medidas como:\n",
        "\n",
        "**Impureza Gini**:\n",
        "\n",
        "$$\n",
        "Gini = 1 - \\sum_{k=1}^K p_k^2\n",
        "$$\n",
        "\n",
        "**Entropía**:\n",
        "\n",
        "$$\n",
        "Entropy = -\\sum_{k=1}^K p_k \\log_2 p_k\n",
        "$$\n",
        "\n",
        "Donde $p_k$ es la proporción de elementos de clase $k$ en el nodo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "qkJttg9J33qo",
      "metadata": {
        "id": "qkJttg9J33qo"
      },
      "outputs": [],
      "source": [
        "def gini_impurity(y):\n",
        "    clases, counts = np.unique(y, return_counts=True)\n",
        "    probas = counts / counts.sum()\n",
        "    return 1 - np.sum(probas ** 2)\n",
        "\n",
        "def entropy(y):\n",
        "    clases, counts = np.unique(y, return_counts=True)\n",
        "    probas = counts / counts.sum()\n",
        "    return -np.sum(probas * np.log2(probas + 1e-9))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RLzWbXwF4lTr",
      "metadata": {
        "id": "RLzWbXwF4lTr"
      },
      "source": [
        "**2. Ganancia de información**\n",
        "\n",
        "Medimos cuánto reduce la impureza al hacer una división:\n",
        "\n",
        "$$\n",
        "Gain(S, A) = Impurity(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} Impurity(S_v)\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "CYoB1TFypdit",
      "metadata": {
        "id": "CYoB1TFypdit"
      },
      "outputs": [],
      "source": [
        "def informacion_ganada(y, y_izq, y_der, criterio='gini'):\n",
        "    if criterio == 'gini':\n",
        "        impureza = gini_impurity\n",
        "    else:\n",
        "        impureza = entropy\n",
        "\n",
        "    n = len(y)\n",
        "    n_izq = len(y_izq)\n",
        "    n_der = len(y_der)\n",
        "\n",
        "    ganancia = impureza(y) - ((n_izq/n)*impureza(y_izq) + (n_der/n)*impureza(y_der))\n",
        "    return ganancia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rRrlLMW44zls",
      "metadata": {
        "id": "rRrlLMW44zls"
      },
      "source": [
        "**3. Búsqueda del mejor split**\n",
        "\n",
        "Para cada atributo y umbral, se calcula la ganancia de información y se selecciona el mejor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9yilW4zg43Ng",
      "metadata": {
        "id": "9yilW4zg43Ng"
      },
      "outputs": [],
      "source": [
        "def mejor_split(X, y, criterio='gini'):\n",
        "    mejor_gain = -1\n",
        "    mejor_atributo = None\n",
        "    mejor_valor = None\n",
        "    m, n = X.shape\n",
        "\n",
        "    for atributo in range(n):\n",
        "        valores = np.unique(X[:, atributo])\n",
        "        for valor in valores:\n",
        "            izq = y[X[:, atributo] <= valor]\n",
        "            der = y[X[:, atributo] > valor]\n",
        "\n",
        "            if len(izq) == 0 or len(der) == 0:\n",
        "                continue\n",
        "\n",
        "            gain = informacion_ganada(y, izq, der, criterio)\n",
        "\n",
        "            if gain > mejor_gain:\n",
        "                mejor_gain = gain\n",
        "                mejor_atributo = atributo\n",
        "                mejor_valor = valor\n",
        "\n",
        "    return mejor_gain, mejor_atributo, mejor_valor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6R1roJyB6PmI",
      "metadata": {
        "id": "6R1roJyB6PmI"
      },
      "source": [
        "**4. Construcción recursiva del árbol**\n",
        "\n",
        "El árbol se construye recursivamente dividiendo los datos hasta que:\n",
        "\n",
        "- todos los ejemplos tienen la misma clase\n",
        "- o se alcanza una profundidad máxima\n",
        "- o no hay mejora en la ganancia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Y-hgXCMo6TXB",
      "metadata": {
        "id": "Y-hgXCMo6TXB"
      },
      "outputs": [],
      "source": [
        "class Nodo:\n",
        "    def __init__(self, atributo=None, valor=None, izquierdo=None, derecho=None, *, clase=None):\n",
        "        self.atributo = atributo\n",
        "        self.valor = valor\n",
        "        self.izquierdo = izquierdo\n",
        "        self.derecho = derecho\n",
        "        self.clase = clase\n",
        "\n",
        "def construir_arbol(X, y, profundidad=0, max_profundidad=5, criterio='gini'):\n",
        "    clases, counts = np.unique(y, return_counts=True)\n",
        "    clase_mayoritaria = clases[np.argmax(counts)]\n",
        "\n",
        "    if len(clases) == 1 or profundidad == max_profundidad:\n",
        "        return Nodo(clase=clase_mayoritaria)\n",
        "\n",
        "    gain, atributo, valor = mejor_split(X, y, criterio)\n",
        "\n",
        "    if gain == 0:\n",
        "        return Nodo(clase=clase_mayoritaria)\n",
        "\n",
        "    indices_izq = X[:, atributo] <= valor\n",
        "    indices_der = X[:, atributo] > valor\n",
        "\n",
        "    hijo_izq = construir_arbol(X[indices_izq], y[indices_izq], profundidad + 1, max_profundidad, criterio)\n",
        "    hijo_der = construir_arbol(X[indices_der], y[indices_der], profundidad + 1, max_profundidad, criterio)\n",
        "\n",
        "    return Nodo(atributo, valor, hijo_izq, hijo_der)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DXwB5bv27Swx",
      "metadata": {
        "id": "DXwB5bv27Swx"
      },
      "source": [
        "**5. Entrenamiento del árbol (train)**\n",
        "\n",
        "El árbol se entrena construyéndolo recursivamente con los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "F5ETS36j7Io4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "F5ETS36j7Io4",
        "outputId": "4eafd65d-750a-4b9a-bcf8-452d1daff9c5"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array([predecir_uno(x, raiz) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m raiz = \u001b[43mconstruir_arbol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_profundidad\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgini\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Predicción\u001b[39;00m\n\u001b[32m     17\u001b[39m y_pred = predecir(x_test, raiz)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mconstruir_arbol\u001b[39m\u001b[34m(X, y, profundidad, max_profundidad, criterio)\u001b[39m\n\u001b[32m     22\u001b[39m indices_der = X[:, atributo] > valor\n\u001b[32m     24\u001b[39m hijo_izq = construir_arbol(X[indices_izq], y[indices_izq], profundidad + \u001b[32m1\u001b[39m, max_profundidad, criterio)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m hijo_der = \u001b[43mconstruir_arbol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_der\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_der\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofundidad\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_profundidad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Nodo(atributo, valor, hijo_izq, hijo_der)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mconstruir_arbol\u001b[39m\u001b[34m(X, y, profundidad, max_profundidad, criterio)\u001b[39m\n\u001b[32m     21\u001b[39m indices_izq = X[:, atributo] <= valor\n\u001b[32m     22\u001b[39m indices_der = X[:, atributo] > valor\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m hijo_izq = \u001b[43mconstruir_arbol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_izq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_izq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofundidad\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_profundidad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m hijo_der = construir_arbol(X[indices_der], y[indices_der], profundidad + \u001b[32m1\u001b[39m, max_profundidad, criterio)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Nodo(atributo, valor, hijo_izq, hijo_der)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mconstruir_arbol\u001b[39m\u001b[34m(X, y, profundidad, max_profundidad, criterio)\u001b[39m\n\u001b[32m     22\u001b[39m indices_der = X[:, atributo] > valor\n\u001b[32m     24\u001b[39m hijo_izq = construir_arbol(X[indices_izq], y[indices_izq], profundidad + \u001b[32m1\u001b[39m, max_profundidad, criterio)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m hijo_der = \u001b[43mconstruir_arbol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_der\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_der\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofundidad\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_profundidad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Nodo(atributo, valor, hijo_izq, hijo_der)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mconstruir_arbol\u001b[39m\u001b[34m(X, y, profundidad, max_profundidad, criterio)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(clases) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m profundidad == max_profundidad:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Nodo(clase=clase_mayoritaria)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m gain, atributo, valor = \u001b[43mmejor_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gain == \u001b[32m0\u001b[39m:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Nodo(clase=clase_mayoritaria)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mmejor_split\u001b[39m\u001b[34m(X, y, criterio)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(izq) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(der) == \u001b[32m0\u001b[39m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m gain = \u001b[43minformacion_ganada\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mizq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gain > mejor_gain:\n\u001b[32m     19\u001b[39m     mejor_gain = gain\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36minformacion_ganada\u001b[39m\u001b[34m(y, y_izq, y_der, criterio)\u001b[39m\n\u001b[32m      8\u001b[39m n_izq = \u001b[38;5;28mlen\u001b[39m(y_izq)\n\u001b[32m      9\u001b[39m n_der = \u001b[38;5;28mlen\u001b[39m(y_der)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m ganancia = impureza(y) - ((n_izq/n)*\u001b[43mimpureza\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_izq\u001b[49m\u001b[43m)\u001b[49m + (n_der/n)*impureza(y_der))\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ganancia\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mgini_impurity\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgini_impurity\u001b[39m(y):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     clases, counts = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     probas = counts / counts.sum()\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m - np.sum(probas ** \u001b[32m2\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Equipo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py:286\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    284\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Equipo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py:353\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[39m\n\u001b[32m    351\u001b[39m     aux = ar[perm]\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     ar.sort()\n\u001b[32m    354\u001b[39m     aux = ar\n\u001b[32m    355\u001b[39m mask = np.empty(aux.shape, dtype=np.bool)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "def predecir_uno(x, nodo):\n",
        "    while nodo.clase is None:\n",
        "        if x[nodo.atributo] <= nodo.valor:\n",
        "            nodo = nodo.izquierdo\n",
        "        else:\n",
        "            nodo = nodo.derecho\n",
        "    return nodo.clase\n",
        "\n",
        "def predecir(X, raiz):\n",
        "    return np.array([predecir_uno(x, raiz) for x in X])\n",
        "\n",
        "\n",
        "# Entrenamiento\n",
        "raiz = construir_arbol(x_train, y_train, max_profundidad=5, criterio='gini')\n",
        "\n",
        "# Predicción\n",
        "y_pred = predecir(x_test, raiz)\n",
        "\n",
        "# Evaluación\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Healthy\", \"Unhealthy\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d48a85859c28c0",
      "metadata": {
        "id": "e8d48a85859c28c0"
      },
      "source": [
        "## Métricas\n",
        "\n",
        "\n",
        "| **Métrica**          | **Descripción**                                                                 | **Enlace a la documentación y ejemplos**                        |\n",
        "|-----------------------|-------------------------------------------------------------------------------|----------------------------------------------------------------|\n",
        "| **Accuracy**          | Proporción de predicciones correctas respecto al total de muestras.            | [Accuracy - scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) |\n",
        "| **Precision**         | Proporción de predicciones positivas correctas respecto a todas las predicciones positivas. | [Precision - scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) |\n",
        "| **Recall (Sensibilidad)** | Proporción de positivos reales identificados correctamente.                    | [Recall - scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) |\n",
        "| **F1-Score**          | Media armónica entre la Precision y el Recall, útil para datos desbalanceados. | [F1-Score - scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) |\n",
        "\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vhFKKBFbASQz",
      "metadata": {
        "id": "vhFKKBFbASQz"
      },
      "source": [
        "Una vez terminado de llenar las funciones del modelo seleccionado, programe el test y utilice el train y test en su modelo. Es necesario que mida a su modelo usando las métricas proporcionadas (Accuracy, Precision, Recall, F1-Score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d72fbc8d2c715f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-02T07:42:12.718537Z",
          "start_time": "2025-05-02T07:42:12.715580Z"
        },
        "id": "4d72fbc8d2c715f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score              # Accuracy\n",
        "from sklearn.metrics import precision_score             # Precision\n",
        "from sklearn.metrics import recall_score                # Recall\n",
        "from sklearn.metrics import f1_score                    # F1-Score\n",
        "\n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb84b51d41c41eb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-02T07:42:12.739906Z",
          "start_time": "2025-05-02T07:42:12.729345Z"
        },
        "id": "dfb84b51d41c41eb"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de como usar un reporte de clasificación .\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred, target_names = [\"Healthy\", \"Unhealthy\"])\n",
        "print(\" My Model Metrics  \")\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5bbb667183f9b128",
        "rVA3I_FzkafE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
